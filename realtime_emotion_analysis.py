# -*- coding: utf-8 -*-
"""Realtime_emotion_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MFoVvBnrVrxBT3IQbNIU4YPcyBkTo1cF

# For using kaggle datasets in Colab

1.  **Get Kaggle API Token**

 Login to your Kaggle account and under “My Account”, navigate to “Create New API Token”. Click the button to download your API token as a json file.

2.  **Install Kaggle library**
"""

!pip install -q kaggle

"""3.  **Upload Kaggle API json file to Google Colab**"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!ls ~/.kaggle
!chmod 600 /root/.kaggle/kaggle.json  # set permission

"""4. **Download dataset from Kaggle**"""

!kaggle datasets download -d jonathanoheix/face-expression-recognition-dataset

"""5. **Unzip datasets**"""

!unzip face-expression-recognition-dataset.zip

"""To list the files"""

!ls

"""# Opening and checking image files using opencv and matplotlib"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import cv2
# %matplotlib inline

#To read an image

sad= cv2.imread('images/train/sad/3.jpg')

#To show the image

plt.imshow(sad)

#Check the size of the image

sad.shape

"""# Preparing the Data for the model

There is too much data for us to read all at once in memory. We can use some built in functions in Keras to automatically process the data, generate a flow of batches from a directory, and also manipulate the images.

## Image Manipulation

Its usually a good idea to manipulate the images with rotation, resizing, and scaling so the model becomes more robust to different images that our data set doesn't have. We can use the ImageDataGenerator to do this automatically for us.
"""

from keras.preprocessing.image import ImageDataGenerator

image_gen = ImageDataGenerator(rotation_range=30, # rotate the image 30 degrees
                               width_shift_range=0.1, # Shift the pic width by a max of 10%
                               height_shift_range=0.1, # Shift the pic height by a max of 10%
                               rescale=1/255, # Rescale the image by normalzing it.
                               shear_range=0.2, # Shear means cutting away part of the image (max 20%)
                               zoom_range=0.2, # Zoom in by 20% max
                               horizontal_flip=True, # Allo horizontal flipping
                               fill_mode='nearest' # Fill in missing pixels with the nearest filled value
                              )

"""# Generating many manipulated images from a directory"""

train_image_gen = image_gen.flow_from_directory('images/train',
                                               target_size=(48,48),
                                               color_mode='grayscale',
                                               batch_size=128,
                                               class_mode='categorical',
                                                shuffle=True)
test_image_gen = image_gen.flow_from_directory('images/validation',
                                               target_size=(48,48),
                                               color_mode='grayscale',
                                               batch_size=128,
                                               class_mode='categorical',
                                                shuffle=True)

"""# Creating the model"""

from keras.layers import Conv2D #Convolution operation
from keras.layers.normalization import BatchNormalization
from keras.regularizers import l2
from keras.layers import Activation #Applies activation function
from keras.layers import Dropout #Prevents overfitting by randomly converting few outputs to zero
from keras.layers import MaxPooling2D # Maxpooling function
from keras.layers import Flatten # Converting 2D arrays into a 1D linear vector
from keras.layers import Dense # Regular fully connected neural network
from keras import optimizers
from sklearn.metrics import accuracy_score
from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Model, Sequential
from keras.optimizers import Adam

#PARAMATERS
epochs = 100
batch_size = 64
learning_rate = 0.001

model = Sequential()
    
model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1), kernel_regularizer=l2(0.01)))
model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))
model.add(Dropout(0.5))

model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.5))
    
model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.5))

model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.5))
    
model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(7, activation='softmax'))
adam = optimizers.Adam(lr = learning_rate)
model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])

model.summary()

"""# Training the model"""

results=model.fit_generator(generator=train_image_gen,
                            steps_per_epoch=200,
                            epochs=100,
                            validation_data=test_image_gen,
                            validation_steps=150)

"""# Evaluating the model"""

plt.plot(results.history['acc'])

"""Saved the model to my Google drive so that I can reuse it and also download to my local computer.

It is always a good idea to save and use model for real time detection.
"""